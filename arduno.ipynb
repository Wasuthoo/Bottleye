{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import serial.tools.list_ports\n",
    "\n",
    "available_ports = list(serial.tools.list_ports.comports())\n",
    "\n",
    "if not available_ports:\n",
    "    print(\"No serial ports found.\")\n",
    "else:\n",
    "    for port in available_ports:\n",
    "        print(f\"Available Port: {port.device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import serial\n",
    "\n",
    "# Change the serial port to match your Arduino's port\n",
    "ser = serial.Serial('COM5', 9600)  # Windows example, on Linux use '/dev/ttyACM0'\n",
    "\n",
    "def send_command(command):\n",
    "    ser.write(command.encode())\n",
    "    response = ser.readline().decode().strip()\n",
    "    return response\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        cmd = input(\"Enter command (C: Check Water, Q: Quit): \")\n",
    "        if cmd == 'Q':\n",
    "            break\n",
    "        elif cmd == 'C':\n",
    "            response = send_command('C')\n",
    "            print(\"Arduino Response:\", response)\n",
    "        else:\n",
    "            print(\"Invalid command. Use 'C' or 'Q.\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Program terminated.\")\n",
    "finally:\n",
    "    ser.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i want image file save to buffer waiting for image classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
    "import cv2\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Create a global buffer to store the captured image\n",
    "image_buffer = None\n",
    "\n",
    "@app.post(\"/capture\")\n",
    "async def capture_image(file: UploadFile):\n",
    "    global image_buffer\n",
    "    # Check if the uploaded file is an image (you can add more validation here).\n",
    "    if not file.filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        raise HTTPException(status_code=400, detail=\"Only image files (JPEG or PNG) are supported.\")\n",
    "\n",
    "    # Read the image from the webcam.\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "\n",
    "    if not ret:\n",
    "        raise HTTPException(status_code=500, detail=\"Failed to capture image from the webcam.\")\n",
    "\n",
    "    # Convert the image to bytes and store it in the global buffer\n",
    "    _, buffer = cv2.imencode(\".jpg\", frame)\n",
    "    image_buffer = buffer.tobytes()\n",
    "\n",
    "    # Save the uploaded file (if needed)\n",
    "    with open(file.filename, \"wb\") as f:\n",
    "        f.write(file.file.read())\n",
    "\n",
    "    return {\"message\": \"Image captured and stored for classification\"}\n",
    "\n",
    "@app.get(\"/process_image\")\n",
    "async def process_image():\n",
    "    global image_buffer\n",
    "\n",
    "    if image_buffer is not None:\n",
    "        # Simulate image classification here, you can replace this with your actual model\n",
    "        # In this example, we're just returning the image as a response\n",
    "        return {\"image\": image_buffer}\n",
    "    else:\n",
    "        raise HTTPException(status_code=404, detail=\"No captured image available for processing\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "def capture_image():\n",
    "    # Capture an image from the webcam.\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    \n",
    "    # Set the capture resolution to achieve a widescreen aspect ratio (16:9).\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)  # Set the width to 1920 pixels\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)  # Set the height to 1080 pixels\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "\n",
    "    if not ret:\n",
    "        return None\n",
    "\n",
    "    # Convert the image to bytes.\n",
    "    _, buffer = cv2.imencode(\".jpg\", frame)\n",
    "    img_bytes = buffer.tobytes()\n",
    "\n",
    "    return img_bytes\n",
    "\n",
    "# Capture the image\n",
    "image_bytes = capture_image()\n",
    "\n",
    "if image_bytes:\n",
    "    # Open the image using PIL\n",
    "    image = Image.open(io.BytesIO(image_bytes))\n",
    "    \n",
    "    # Display the image\n",
    "    image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import serial\n",
    "\n",
    "# Change the serial port to match your Arduino's port\n",
    "ser = serial.Serial('COM5', 9600)  # Windows example, on Linux use '/dev/ttyACM0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_command(command):\n",
    "        ser.write(command.encode())\n",
    "        response = ser.readline().decode().strip()\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_command('C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"my_model.h5\") # Specify the correct file path when loading the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_func(img):\n",
    "    # plt.figure(figsize=(6,4))\n",
    "    # plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    # plt.tight_layout()\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = np.reshape(img, [-1, 224, 224,3])\n",
    "    result = np.argmax(model.predict(img))\n",
    "    if result == 0: print(\"\\033[94m\"+\"This image -> Not Bottle\"+\"\\033[0m\")\n",
    "    elif result ==1: print(\"\\033[94m\"+\"This image -> Bottle\"+\"\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 130ms/step\n",
      "\u001b[94mThis image -> Not Bottle\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "test_img = cv2.imread(\"img\\captured_image.jpg\")\n",
    "predict_func(test_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
